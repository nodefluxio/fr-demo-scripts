{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFa5VyVNPCJY"
      },
      "source": [
        "# Nodeflux Face Recognition DEMO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qg7V4zoPCJi"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "Welcome! In this demo, you will experience the nodeflux's Face Recognition products."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dependencies\n",
        "\n",
        "Run below script once to install all required dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install pillow\n",
        "%pip install gradio\n",
        "%pip install requests\n",
        "%pip install names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_mbLFq9Vvcg"
      },
      "source": [
        "## Face Match (1:1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Matching Script"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io4CCbvZ-220"
      },
      "source": [
        "#### Description\n",
        "\n",
        "This step demonstrates, stateless face matching between two face photos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title #### Fremis Config\n",
        "FREMIS_ADDRESS = \"192.168.103.46\" # @param {type:\"string\"}\n",
        "FREMIS_PORT = \"2210\" # @param {type:\"string\"}\n",
        "FM_ENDPOINT = \"v1/face/match\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "H5LA1LcdPCJm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "import base64\n",
        "import requests\n",
        "import json\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "url = f\"http://{FREMIS_ADDRESS}:{FREMIS_PORT}/{FM_ENDPOINT}\"\n",
        "\n",
        "def image2base64(image):\n",
        "    img_byte_array = BytesIO()\n",
        "    image.save(img_byte_array, format='JPEG')\n",
        "    img_byte_array = img_byte_array.getvalue()\n",
        "    \n",
        "    return base64.b64encode(img_byte_array).decode('utf-8')\n",
        "\n",
        "\n",
        "def match(source_image, target_image):\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    payload = json.dumps({\n",
        "        'image_a': {\n",
        "            'content': image2base64(source_image)\n",
        "        },\n",
        "        'image_b': {\n",
        "            'content': image2base64(target_image)\n",
        "        }\n",
        "    })\n",
        "\n",
        "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "    return response.json()\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=match,  \n",
        "    inputs=[gr.Image(type=\"pil\"), gr.Image(type=\"pil\")],\n",
        "    outputs=\"json\", \n",
        "    title=\"Face Match\",\n",
        "    examples=[\n",
        "        [\"images/source/Guido.jpeg\",\"images/target/Guido.jpeg\"],\n",
        "        [\"images/source/Jensen.jpeg\",\"images/target/Jackie.jpeg\"],\n",
        "        [\"images/source/LeCun.jpeg\",\"images/target/LeCun.jpeg\"],\n",
        "    ],\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZBnPIJdVlYG"
      },
      "source": [
        "## Face Search (1:N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Script Enrollment - Mode 1: Embedding Only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2wOiPqDiojo"
      },
      "source": [
        "#### Description\n",
        "In this mode, the script demonstrates how to enroll a face and save the extracted embedding on Fremis Platform directly. At this point, no users data other than [face embedding](https://medium.com/mlearning-ai/face-embedding-and-what-you-need-to-know-a623c7111b5#:~:text=Face%20embedding%20is%20the%20way,%2C%20similarity%2C%20or%20face%20search.) will be recorded. The user is REQUIRED to remember the FACE ID in order to update or adding new variations on the same FACE ID."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title #### Fremis Config\n",
        "FREMIS_ADDRESS = \"192.168.103.46\" # @param {type:\"string\"}\n",
        "FREMIS_PORT = \"2210\" # @param {type:\"string\"}\n",
        "FE_ENDPOINT = \"v1/face/enrollment\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fsMSIbrwTKuB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7904\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7904/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "import base64\n",
        "import requests\n",
        "import json\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "url = f\"http://{FREMIS_ADDRESS}:{FREMIS_PORT}/{FE_ENDPOINT}\"\n",
        "\n",
        "def image2base64(image):\n",
        "    img_byte_array = BytesIO()\n",
        "    image.save(img_byte_array, format='JPEG')\n",
        "    img_byte_array = img_byte_array.getvalue()\n",
        "    \n",
        "    return base64.b64encode(img_byte_array).decode('utf-8')\n",
        "\n",
        "\n",
        "def enroll(image):\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    payload = json.dumps({\n",
        "        'image': image2base64(image),\n",
        "        'keyspace': 'default'\n",
        "    })\n",
        "\n",
        "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "    return response.json()\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=enroll,  \n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=\"json\", \n",
        "    title=\"Face Enrollment\",\n",
        "    examples=[\n",
        "        \"images/source/Guido.jpeg\",\n",
        "        \"images/source/Jensen.jpeg\",\n",
        "        \"images/source/LeCun.jpeg\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Script Enrollment - Mode 2: User Dashboard Enrollment Management API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iooYxZRr-222"
      },
      "source": [
        "#### Description\n",
        "In this mode, the script demonstrates on how to enroll a face via Client Dashboard's API (this example is using Nodeflux Sample Dashboard called Vanilla). Using this approach, the user will able to map the enrolled [face embedding](https://medium.com/mlearning-ai/face-embedding-and-what-you-need-to-know-a623c7111b5#:~:text=Face%20embedding%20is%20the%20way,%2C%20similarity%2C%20or%20face%20search.) with other data such as Name, Identity Number, Status, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title #### Fremis Config\n",
        "VANILLA_ADDRESS = \"192.168.103.46\" # @param {type:\"string\"}\n",
        "VANILLA_PORT = \"8008\" # @param {type:\"string\"}\n",
        "FE_ENDPOINT = \"api/enrollment\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7861\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "import requests\n",
        "import names\n",
        "from PIL import Image\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "url = f\"http://{VANILLA_ADDRESS}:{VANILLA_PORT}/{FE_ENDPOINT}\"\n",
        "\n",
        "def image2bin(image):\n",
        "    img_byte_array = BytesIO()\n",
        "    image.save(img_byte_array, format='JPEG')\n",
        "    return img_byte_array.getvalue()\n",
        "\n",
        "\n",
        "def dashboard_enroll(image):\n",
        "    payload = {\n",
        "        'name': names.get_full_name(),\n",
        "        'identity_number': '123456789',\n",
        "        'gender': 'male',\n",
        "        'birth_date': '2000-12-01',\n",
        "        'birth_place': 'Abu Dhabi',\n",
        "        'status': 'wanted'\n",
        "    }\n",
        "\n",
        "    files = {\n",
        "        ('images',('test.jpeg',image2bin(image),'image/jpeg'))\n",
        "    }\n",
        "\n",
        "    response = requests.request(\"POST\", url, data=payload, files=files)\n",
        "    res = response.json() \n",
        "    img_thumb = None\n",
        "\n",
        "    try:\n",
        "        base64_image_string = res['enrollment']['faces'][0]['image_thumbnail']\n",
        "        decoded_bytes = base64.b64decode(base64_image_string)\n",
        "        image_stream = BytesIO(decoded_bytes)\n",
        "        img_thumb = Image.open(image_stream)\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return res, img_thumb\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=dashboard_enroll,  \n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[\"json\", gr.Image(type=\"pil\")], \n",
        "    title=\"Face Enrollment via Dashboard API\",\n",
        "    examples=[\n",
        "        \"images/source/Guido.jpeg\",\n",
        "        \"images/source/Jensen.jpeg\",\n",
        "        \"images/source/LeCun.jpeg\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Script Face Recognition (1:N Search)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Description\n",
        "In this mode, the script demonstrates on how to search a enrolled / recognized face via Fremis Platform API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title #### Fremis Config\n",
        "FREMIS_ADDRESS = \"192.168.103.46\" # @param {type:\"string\"}\n",
        "FREMIS_PORT = \"2210\" # @param {type:\"string\"}\n",
        "FR_ENDPOINT = \"v1/face/recognition\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7907\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7907/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from io import BytesIO\n",
        "import base64\n",
        "import requests\n",
        "import json\n",
        "\n",
        "import gradio as gr\n",
        "\n",
        "url = f\"http://{FREMIS_ADDRESS}:{FREMIS_PORT}/{FR_ENDPOINT}\"\n",
        "\n",
        "def image2base64(image):\n",
        "    img_byte_array = BytesIO()\n",
        "    image.save(img_byte_array, format='JPEG')\n",
        "    img_byte_array = img_byte_array.getvalue()\n",
        "    \n",
        "    return base64.b64encode(img_byte_array).decode('utf-8')\n",
        "\n",
        "\n",
        "def recognize(image):\n",
        "    headers = {\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    payload = json.dumps({\n",
        "        'image': image2base64(image),\n",
        "        'keyspace': 'default'\n",
        "    })\n",
        "\n",
        "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "    return response.json()\n",
        "\n",
        "iface = gr.Interface(\n",
        "    fn=recognize,  \n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=\"json\", \n",
        "    title=\"Face Recognition\",\n",
        "    examples=[\n",
        "        \"images/source/Guido.jpeg\",\n",
        "        \"images/source/Jensen.jpeg\",\n",
        "        \"images/source/LeCun.jpeg\",\n",
        "    ],\n",
        ")\n",
        "\n",
        "iface.launch()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
